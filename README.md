# 纯数字语音验证码识别研发
##  1. 纯数字语音识别算法简介
基于开源项目SphereFace深度学习算法进行开发，采用了主流的Pytorch深度学习框架对算法进行了实现。本算法采用卷积神经网络（CNN）、门控机制（GLU）和连接性时序分类（CTC）的方法，使用中文数字语音数据集进行训练，将数字语音转录为拼音，并通过语言模型，将拼音序列转换为数字。

训练方法：使用无重复纯语音数据集训练ASRT模型，总迭代次数设置为：200。训练的硬件环境为：NVIDIA TITAN RTX显卡，显存大小24G。保存训练过程中在验证集上表现最优的模型为最终模型，模型大小为108.7M。

模型评价指标：采用语音识别中常用的字错误率CER来衡量模型的性能，CER=编辑距离/句子长度，越低越好，大致可以理解1-CER为识别准确率。
##  2. 数据集
基于Q学友重复语音数据集和无重复语音数据集进行研发，为了排除异常语音数据的干扰，预先对语音数据集进行数据处理。针对无重复语音数据集，剔除了时长小于2秒或大于15秒的语音数据，针对重复语音数据集，剔除了时长小于3秒或大于30秒的语音数据。最终获得共116,351条语音数据，按照70%、15%、15%划分训练集、验证集、测试集，具体划分：训练集：81,445、验证集：17,453、测试集：17,453。
## 3. 实验环境
本项目所有实验均在Ubuntu 18.04操作系统下完成和实现，使用了基于Python3.7的TensorFlow深度学习框架，英伟达显卡驱动版本为Driver Version: 440.82，CUDA版本为10.1。下面给出了利用该算法进行推理时依赖的第三方Python库。

- Ubuntu: 18.04 lts
-  Python 3.7.8
- Pytorch 1.6.0
- NVIDIA GPU + CUDA_10.0 CuDNN_7.5

## 4. 实验结果
硬件配置为：单张NVIDIA TITAN RTX显卡，显存大小24G。训练好的模型对整个测试集进行混合并行测试。Tensorflow默认动态占用整块显卡的显存。对17,453个测试样本进行逐条测试，共花费了1002.41s时长，平均每个样本的时间消耗为：57.44ms。字错误率CER=0.104，即识别准确率为1-0. 044=0.896。
如果将每个语音完全识别正确定义为正确识别，则模型测试的识别率为：预测完全正确的样本数：15,819，共测试数据总数：17,453，这样样本完全测试正确的准确率为：0.856。
## 5. 训练与测试
### Train
```
python train.py
```
### Test
```
# qxy.tgz to qxy.zip
tar zxf qxy.tgz; cd qxy; zip -r ../qxy.zip *; cd ..

# lfw evaluation
python lfw_eval.py --model model/sphere_qxy200.pth
```
